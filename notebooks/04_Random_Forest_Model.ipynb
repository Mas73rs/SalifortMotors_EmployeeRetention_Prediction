{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a random forest model and set up cross-validated grid-search to exhuastively search for the best model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "\n",
    "# Adds the project root and utils directory to the PYTHONPATH\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../utils\")  \n",
    "\n",
    "# Imports everything from common_imports.py and config\n",
    "from common_imports import *  \n",
    "from config import *\n",
    "\n",
    "# Load train / test datasets\n",
    "# Train sets\n",
    "X_train = pd.read_csv(X_train_path)\n",
    "y_train = pd.read_csv(y_train_path)\n",
    "\n",
    "# Test sets\n",
    "X_test = pd.read_csv(X_test_path)\n",
    "y_test = pd.read_csv(y_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T18:23:50.145089Z",
     "iopub.status.busy": "2023-09-28T18:23:50.144665Z",
     "iopub.status.idle": "2023-09-28T18:23:50.153513Z",
     "shell.execute_reply": "2023-09-28T18:23:50.152298Z",
     "shell.execute_reply.started": "2023-09-28T18:23:50.145054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "cv_params = {'max_depth' : [1, 3, 5, 10, None],\n",
    "             'max_features' : [0.5, 1.0],\n",
    "             'max_samples' : [0.5, 0.7, 1.0],\n",
    "             'min_samples_leaf' : [1, 2, 5],\n",
    "             'min_samples_split' : [2, 3, 5],\n",
    "             'n_estimators' : [300, 500]}\n",
    "\n",
    "# Scoring\n",
    "scoring = {'accuracy' : 'accuracy',\n",
    "           'precision' : 'precision',\n",
    "           'f1' : 'f1',\n",
    "           'recall' : 'recall',\n",
    "           'roc_auc' : 'roc_auc'}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "rf_cv1 = GridSearchCV(rf, cv_params, scoring=scoring, cv=5, refit='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-28T18:32:44.252126Z",
     "iopub.status.busy": "2023-09-28T18:32:44.25166Z",
     "iopub.status.idle": "2023-09-28T19:25:11.739308Z",
     "shell.execute_reply": "2023-09-28T19:25:11.737395Z",
     "shell.execute_reply.started": "2023-09-28T18:32:44.252087Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Fit the model on test data\n",
    "# rf_cv1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T19:28:28.276402Z",
     "iopub.status.busy": "2023-09-28T19:28:28.275896Z",
     "iopub.status.idle": "2023-09-28T19:28:28.3103Z",
     "shell.execute_reply": "2023-09-28T19:28:28.309016Z",
     "shell.execute_reply.started": "2023-09-28T19:28:28.276363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the model\n",
    "path = random_forest1_path\n",
    "\n",
    "# Read pickle\n",
    "rf1 = read_pickle(path, 'hr_rf1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the best AUC score achieved by the random forest model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T19:28:32.024892Z",
     "iopub.status.busy": "2023-09-28T19:28:32.024166Z",
     "iopub.status.idle": "2023-09-28T19:28:32.031982Z",
     "shell.execute_reply": "2023-09-28T19:28:32.030709Z",
     "shell.execute_reply.started": "2023-09-28T19:28:32.024855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check best AUC score on CV\n",
    "rf1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the optimal values for the parameters of the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T19:28:41.347888Z",
     "iopub.status.busy": "2023-09-28T19:28:41.347354Z",
     "iopub.status.idle": "2023-09-28T19:28:41.356854Z",
     "shell.execute_reply": "2023-09-28T19:28:41.355148Z",
     "shell.execute_reply.started": "2023-09-28T19:28:41.347849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check best params\n",
    "rf1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T19:28:54.396073Z",
     "iopub.status.busy": "2023-09-28T19:28:54.394321Z",
     "iopub.status.idle": "2023-09-28T19:28:54.422869Z",
     "shell.execute_reply": "2023-09-28T19:28:54.42151Z",
     "shell.execute_reply.started": "2023-09-28T19:28:54.396012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get all CV scores\n",
    "rf1_cv_results = make_results('random forest cv', rf1, 'auc')\n",
    "\n",
    "# Update `results` DataFrame\n",
    "results = pd.concat([results, rf1_cv_results], axis=0)\n",
    "\n",
    "# Sort 'results' by F1-score\n",
    "results = results.sort_values(by='F1', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display `results` Dataframe\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T19:32:33.395589Z",
     "iopub.status.busy": "2023-09-28T19:32:33.39494Z",
     "iopub.status.idle": "2023-09-28T19:32:33.557115Z",
     "shell.execute_reply": "2023-09-28T19:32:33.555955Z",
     "shell.execute_reply.started": "2023-09-28T19:32:33.39554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get predictions on test data\n",
    "rf1_test_scores = get_scores('random forest test', rf1, X_test, y_test)\n",
    "\n",
    "# Update `results` DataFrame\n",
    "results = pd.concat([results, rf1_test_scores], axis=0)\n",
    "\n",
    "# Sort 'results' by F1-score\n",
    "results = results.sort_values(by='F1', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Save `results` DataFrame\n",
    "results.to_csv('../model/model_results.csv', index=False)\n",
    "\n",
    "# Display `results` Dataframe\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T19:33:08.91371Z",
     "iopub.status.busy": "2023-09-28T19:33:08.913079Z",
     "iopub.status.idle": "2023-09-28T19:33:08.935473Z",
     "shell.execute_reply": "2023-09-28T19:33:08.934472Z",
     "shell.execute_reply.started": "2023-09-28T19:33:08.913661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pivot the `results` table\n",
    "results_long = pd.melt(results, 'model')\n",
    "results_long = results_long.rename(columns={'variable' : 'metric'})\n",
    "results_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Models' results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T19:56:54.642569Z",
     "iopub.status.busy": "2023-09-28T19:56:54.641036Z",
     "iopub.status.idle": "2023-09-28T19:56:55.62851Z",
     "shell.execute_reply": "2023-09-28T19:56:55.627281Z",
     "shell.execute_reply.started": "2023-09-28T19:56:54.6425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the figure\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# Barplot with Metrics on x-axis and new color scheme ('husl')\n",
    "sns.barplot(x='metric', y='value', hue='model', data=results_long, ax=ax[0])\n",
    "\n",
    "# Find the highest value for each metric to highlight the corresponding bar\n",
    "for metric in results_long['metric'].unique():\n",
    "    highest_value = results_long[results_long['metric'] == metric]['value'].max()\n",
    "    # Highlight the bar with highest value for each metric\n",
    "    for p in ax[0].patches:\n",
    "        if p.get_height() == highest_value and p.get_x() >= list(results_long['metric'].unique()).index(metric) - 0.5:\n",
    "            p.set_edgecolor('black')\n",
    "            p.set_linewidth(1)\n",
    "\n",
    "ax[0].set_title('Bar Chart of Model Evaluation Metrics (Metrics on x-axis)')\n",
    "ax[0].set_ylabel('Value')\n",
    "ax[0].set_xlabel('Metrics')\n",
    "\n",
    "# Move legend to the bottom for the barplot\n",
    "ax[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=5)\n",
    "\n",
    "# Line Graph with Metrics on x-axis and new color scheme ('dark')\n",
    "sns.lineplot(x='metric', y='value', hue='model', data=results_long, ax=ax[1], marker='o')\n",
    "ax[1].set_title('Line Graph of Model Evaluation Metrics (Metrics on x-axis)')\n",
    "ax[1].set_ylabel('Value')\n",
    "ax[1].set_xlabel('Metrics')\n",
    "\n",
    "# Remove legend from the line graph\n",
    "ax[1].legend_.remove()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Choices Based on Metrics:\n",
    "\n",
    "`Random Forest Test`:Excels in Precision, F1 Score, and Accuracy. This model is less likely to falsely identify loyal employees as risks and offers an excellent general-purpose solution.\n",
    "\n",
    "`Decision Tree Test`: Best in Recall. This model would be suitable if the company is more focused on capturing as many flight risks as possible, even at the risk of some false positives.\n",
    "\n",
    "`Random Forest CV`:Best in AUC. This suggests that the model is excellent in differentiating between the classes. \n",
    "\n",
    "\n",
    "### Recommendation:\n",
    "\n",
    "Given the high costs associated with false positives (misidentifying loyal employees) and false negatives (failing to identify employees who will leave), a balanced approach might be best.\n",
    "`Random Forest Test` is the most balanced model, excelling in precision, F1 score, and accuracy. It's less likely to misclassify employees, enabling the HR department to take targeted actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T19:34:00.870102Z",
     "iopub.status.busy": "2023-09-28T19:34:00.86963Z",
     "iopub.status.idle": "2023-09-28T19:34:01.30486Z",
     "shell.execute_reply": "2023-09-28T19:34:01.303467Z",
     "shell.execute_reply.started": "2023-09-28T19:34:00.870067Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate array of values for confusion matrix\n",
    "preds = rf1.best_estimator_.predict(X_test)\n",
    "cm = confusion_matrix(y_test, preds, labels=rf1.classes_)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=rf1.classes_)\n",
    "disp.plot(values_format='');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpretation:\n",
    "\n",
    "* High True Negative (TN): The model correctly identified a large number of employees who are not at risk of quitting or getting fired (TN = 2316). This is a strong indicator that the model is effective at ruling out employees who are not at risk.\n",
    "* High True Positive (TP): The model also correctly identified a substantial number of employees who are at risk (TP = 434). This shows that the model is also effective at flagging employees who are actually at risk.\n",
    "* Low False Positive (FP): The model incorrectly flagged only a small number of employees as being at risk when they are not (FP = 37). This could lead to unnecessary interventions but is relatively low.\n",
    "* Low False Negative (FN): The model missed a very low number of employees who are at risk but were classified as not being at risk (FN = 5). This is also a good sign, as missing at-risk employees could have been detrimental.\n",
    "\n",
    "Overall, this is a robust model for identifying employees who are and are not at risk of quitting or getting fired, with a low rate of false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-28T20:33:10.31631Z",
     "iopub.status.busy": "2023-09-28T20:33:10.315831Z",
     "iopub.status.idle": "2023-09-28T20:33:10.694236Z",
     "shell.execute_reply": "2023-09-28T20:33:10.692986Z",
     "shell.execute_reply.started": "2023-09-28T20:33:10.316277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feat_impt = rf1.best_estimator_.feature_importances_\n",
    "\n",
    "# Get indices of top 10 features\n",
    "ind = np.argpartition(rf1.best_estimator_.feature_importances_, -10)[-10:]\n",
    "\n",
    "# Get column labels of top 10 features \n",
    "feat = X.columns[ind]\n",
    "\n",
    "# Filter `feat_impt` to consist of top 10 feature importances\n",
    "feat_impt = feat_impt[ind]\n",
    "\n",
    "y_df = pd.DataFrame({\"Feature\":feat,\"Importance\":feat_impt})\n",
    "y_sort_df = y_df.sort_values(\"Importance\")\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "y_sort_df.plot(kind='barh',ax=ax1,x=\"Feature\",y=\"Importance\")\n",
    "\n",
    "ax1.set_title(\"Random Forest: Feature Importances for Employee Leaving\", fontsize=12)\n",
    "ax1.set_ylabel(\"Feature\")\n",
    "ax1.set_xlabel(\"Importance\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
