{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/thierrymasters/salifort-motors-employee-retention-prediction?scriptVersionId=144605639\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Data-driven suggestions for Salifort Motors HR**","metadata":{"id":"ysS5rgTMWpwL"}},{"cell_type":"markdown","source":"## Business Understanding\n\nThe HR department at Salifort Motors is taking positive steps to enhance employee satisfaction levels, which is encouraging. To understand why an employee might leave the company, it's crucial to review the data collected by HR and create a model that can accurately predict the likelihood of an employee departing. This approach enables us to determine the reasons behind their departure and take corrective measures. Since finding, interviewing, and hiring new employees can be time-consuming and costly, increasing employee retention is essential. The company can benefit in various ways by doing so.","metadata":{}},{"cell_type":"markdown","source":"## Data Understanding\n\nThe dataset that you'll be using in this lab contains 15,000 rows and 10 columns for the variables listed below. \n\n\n\n\n**source:** For more information about the data, refer to its source on [Kaggle](https://www.kaggle.com/datasets/mfaisalqureshi/hr-analytics-and-job-prediction?select=HR_comma_sep.csv).","metadata":{"id":"lnRdR6eacUkK"}},{"cell_type":"markdown","source":"Variable  |Description |\n-----|-----|\nsatisfaction_level|Employee-reported job satisfaction level [0&ndash;1]|\nlast_evaluation|Score of employee's last performance review [0&ndash;1]|\nnumber_project|Number of projects employee contributes to|\naverage_monthly_hours|Average number of hours employee worked per month|\ntime_spend_company|How long the employee has been with the company (years)\nWork_accident|Whether or not the employee experienced an accident while at work\nleft|Whether or not the employee left the company\npromotion_last_5years|Whether or not the employee was promoted in the last 5 years\nDepartment|The employee's department\nsalary|The employee's salary (U.S. dollars)","metadata":{}},{"cell_type":"markdown","source":"### Import packages","metadata":{"id":"51UAXIOLC_8P"}},{"cell_type":"code","source":"# Import packages\n\n# Functional packages\nimport pandas as pd\nimport numpy as np\n\n# Data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Build model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Metrics and other functions\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score,\\\nf1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.tree import plot_tree\n\n# For display all columns in dataframes\npd.set_option('display.max_columns', None)\n\n# Saving model\nimport pickle\n\n# Warnings \nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"hVWGpX9As4e1","execution":{"iopub.status.busy":"2023-09-28T18:32:23.380263Z","iopub.execute_input":"2023-09-28T18:32:23.38077Z","iopub.status.idle":"2023-09-28T18:32:23.390274Z","shell.execute_reply.started":"2023-09-28T18:32:23.380734Z","shell.execute_reply":"2023-09-28T18:32:23.388528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load dataset\n","metadata":{"id":"zM2P9yLWDIjN"}},{"cell_type":"code","source":"# Load dataset into a dataframe\ndf_raw= pd.read_csv(\"/kaggle/input/hr-analytics-and-job-prediction/HR_comma_sep.csv\")\n\n# Display first few rows of the dataframe\ndf_raw.head()","metadata":{"id":"Bs0cJR5BDPgQ","execution":{"iopub.status.busy":"2023-09-28T16:22:28.394322Z","iopub.execute_input":"2023-09-28T16:22:28.395068Z","iopub.status.idle":"2023-09-28T16:22:28.49627Z","shell.execute_reply.started":"2023-09-28T16:22:28.395018Z","shell.execute_reply":"2023-09-28T16:22:28.494912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initial EDA and data cleaning\n\n- Understand your variables\n- Clean your dataset (missing data, redundant data, outliers)\n\n","metadata":{"id":"wF_LLorPs5G_"}},{"cell_type":"code","source":"# Basic information about the data\ndf_raw.info()","metadata":{"id":"6XbfdPoKurMf","execution":{"iopub.status.busy":"2023-09-28T16:34:07.064449Z","iopub.execute_input":"2023-09-28T16:34:07.064845Z","iopub.status.idle":"2023-09-28T16:34:07.081467Z","shell.execute_reply.started":"2023-09-28T16:34:07.064794Z","shell.execute_reply":"2023-09-28T16:34:07.080166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Descriptive statistics about the data\ndf_raw.describe()","metadata":{"id":"_5VRL-kzE8y1","execution":{"iopub.status.busy":"2023-09-28T16:34:10.551332Z","iopub.execute_input":"2023-09-28T16:34:10.551821Z","iopub.status.idle":"2023-09-28T16:34:10.598914Z","shell.execute_reply.started":"2023-09-28T16:34:10.551782Z","shell.execute_reply":"2023-09-28T16:34:10.597655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rename columns","metadata":{"id":"QR7eFNU0FklJ"}},{"cell_type":"markdown","source":"We inspect the columns names to see if the are names that stand out or need to be modified","metadata":{}},{"cell_type":"code","source":"# Display all column names\ndf_raw.columns","metadata":{"id":"kEn21u2bqrEI","execution":{"iopub.status.busy":"2023-09-28T16:34:44.99661Z","iopub.execute_input":"2023-09-28T16:34:44.997032Z","iopub.status.idle":"2023-09-28T16:34:45.006954Z","shell.execute_reply.started":"2023-09-28T16:34:44.996999Z","shell.execute_reply":"2023-09-28T16:34:45.005024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename columns\ndf_raw = df_raw.rename(columns={\"Work_accident\" : \"work_accident\",\n                                \"time_spend_company\" : \"tenure\",\n                                \"average_montly_hours\" : \"average_monthly_hours\",\n                                \"Department\" : \"department\"})\n\n# Display all column names after the update\ndf_raw.columns","metadata":{"id":"npUQA8jMFJQD","execution":{"iopub.status.busy":"2023-09-28T16:34:59.650055Z","iopub.execute_input":"2023-09-28T16:34:59.650474Z","iopub.status.idle":"2023-09-28T16:34:59.662986Z","shell.execute_reply.started":"2023-09-28T16:34:59.650439Z","shell.execute_reply":"2023-09-28T16:34:59.661785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Missing values","metadata":{"id":"e-G2QlQxBq__"}},{"cell_type":"code","source":"# Check for missing values\ndf_raw.isna().sum()","metadata":{"id":"EN9MvN0GByVV","execution":{"iopub.status.busy":"2023-09-28T16:36:14.042967Z","iopub.execute_input":"2023-09-28T16:36:14.043368Z","iopub.status.idle":"2023-09-28T16:36:14.058309Z","shell.execute_reply.started":"2023-09-28T16:36:14.043337Z","shell.execute_reply":"2023-09-28T16:36:14.056703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no missing values.","metadata":{}},{"cell_type":"markdown","source":"### Duplicates","metadata":{"id":"hBvrijItKQI9"}},{"cell_type":"code","source":"# Check for duplicates\nduplucates = df_raw.duplicated()\nprint(f'Duplicates : {duplucates.sum()} \\nPercentage : {duplucates.sum() / len(df_raw) * 100 :.2f} %')","metadata":{"id":"CFFLc5AOZ7-x","execution":{"iopub.status.busy":"2023-09-28T16:36:39.776866Z","iopub.execute_input":"2023-09-28T16:36:39.777332Z","iopub.status.idle":"2023-09-28T16:36:39.796976Z","shell.execute_reply.started":"2023-09-28T16:36:39.777297Z","shell.execute_reply":"2023-09-28T16:36:39.795374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have identified 3008 duplicate entries, which account for 20% of the total data set. It is important to take this proportion into consideration when managing the duplicates in order to maintain the integrity of the data. Let's begin by examining a few of the duplicate entries.","metadata":{}},{"cell_type":"code","source":"# Inspect some rows containing duplicates as needed\ndf_raw[duplucates].head()","metadata":{"id":"ZHGlDbKAcBLM","execution":{"iopub.status.busy":"2023-09-28T16:39:36.735564Z","iopub.execute_input":"2023-09-28T16:39:36.73596Z","iopub.status.idle":"2023-09-28T16:39:36.758215Z","shell.execute_reply.started":"2023-09-28T16:39:36.735929Z","shell.execute_reply":"2023-09-28T16:39:36.756845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's drop the duplicates.","metadata":{}},{"cell_type":"code","source":"# Drop duplicates and save resulting dataframe in a new variable as needed\ndf = df_raw.drop_duplicates(keep='first')\n\n# Display first few rows of new dataframe as needed\ndf.head()","metadata":{"id":"wCr34Rppdjay","execution":{"iopub.status.busy":"2023-09-28T16:39:50.446306Z","iopub.execute_input":"2023-09-28T16:39:50.446733Z","iopub.status.idle":"2023-09-28T16:39:50.47413Z","shell.execute_reply.started":"2023-09-28T16:39:50.446698Z","shell.execute_reply":"2023-09-28T16:39:50.472693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Outliers","metadata":{"id":"4knHIoTIFu83"}},{"cell_type":"markdown","source":"First, we examine the boxpot of the `tenure` column for any outliers.","metadata":{}},{"cell_type":"code","source":"# Create a boxplot to visualize distribution of `tenure` and detect any outliers\nfig, ax = plt.subplots(figsize=(6, 4))\nax = sns.boxplot(x='tenure', data=df)\nax.set_title(\"Boxplot to detect outlier for Tenure\")\nplt.show;","metadata":{"id":"pilaGYgh4LHM","execution":{"iopub.status.busy":"2023-09-28T16:40:25.623054Z","iopub.execute_input":"2023-09-28T16:40:25.623474Z","iopub.status.idle":"2023-09-28T16:40:25.921771Z","shell.execute_reply.started":"2023-09-28T16:40:25.623408Z","shell.execute_reply":"2023-09-28T16:40:25.920479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we define a function to calculate the number of outliers in a selected column.","metadata":{}},{"cell_type":"code","source":"# Determine the number of rows containing outliers\n\ndef num_outliers(column):\n    \"\"\"\n        This function takes as parameter a column of the dataset and does the following:\n         - computes its 25th and 75th percentiles\n         - determine the interquantile range\n         - define the upper and lower limits for non_outlier values\n         - count and print the number of outlier\n        \n        Formulas:\n        interquantile range (iqr): 75th percentile - 25th percentile\n        upper limit : 75th percentile + 1.5 * iqr\n        lower limit : 25th percentile - 1.5 * iqr\n\n    \"\"\"\n\n    # Compute 25th percentile\n    percent_25 = df[column].quantile(0.25)\n\n    # Compute 75th percentile\n    percent_75 = df[column].quantile(0.75)\n\n    # Compute interquantile range\n    iqr = percent_75 - percent_25\n\n    # Define upper and lower limits for non-oulier values in column\n    upper_limit = percent_75 + 1.5 * iqr\n    lower_limit = percent_25 - 1.5 * iqr\n    print(f'Upper Limit : {upper_limit}')\n    print(f'Lower Limit : {lower_limit}')\n\n    # Identify the subset of data containing outliers\n    outliers = df[(df[column] > upper_limit) | (df[column] < lower_limit)]\n\n    # Count number of rows with outliers\n    print(f\"Number of Outliers in '{column}' : {len(outliers)} \")\n","metadata":{"id":"ohctgiHyFykI","execution":{"iopub.status.busy":"2023-09-28T16:40:49.569914Z","iopub.execute_input":"2023-09-28T16:40:49.570385Z","iopub.status.idle":"2023-09-28T16:40:49.580163Z","shell.execute_reply.started":"2023-09-28T16:40:49.570347Z","shell.execute_reply":"2023-09-28T16:40:49.579268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now inquire the number of outliers in `tenure` column.","metadata":{}},{"cell_type":"code","source":"# Number of rows with outliers in 'tenure'\nnum_outliers('tenure')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Different models have varying sensitivity to outliers. Once we reach the model-building stage, we will assess the need to eliminate outliers depending on the specific model we opt to utilise.","metadata":{"id":"eP_rPN31Kmx0"}},{"cell_type":"markdown","source":"## Data Exploration (Continue EDA)\n\nwe will begin by understanding how many employees left and what percentage of all employees this figure represents.","metadata":{"id":"KDcWrk57kao2"}},{"cell_type":"code","source":"# Get numbers of people who left vs. stayed\nnum_left = len(df[df['left'] == 1])\nnum_stayed = len(df) - num_left\nprint(f\"Number of employees that left : {num_left}\")\nprint(f\"Number of employees that stayed : {num_stayed}\")\n\n# Get percentages of people who left vs. stayed\nprint(f\"Percentage leaving : {num_left / len(df) * 100 :.2f} %\")\nprint(f\"Percentage staying : {num_stayed / len(df) * 100 :.2f} %\")","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:01:33.871828Z","iopub.execute_input":"2023-09-28T17:01:33.87254Z","iopub.status.idle":"2023-09-28T17:01:33.885778Z","shell.execute_reply.started":"2023-09-28T17:01:33.872488Z","shell.execute_reply":"2023-09-28T17:01:33.884358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 16.6% employees leaving the company. That is close to a fifth of total number of employees.","metadata":{}},{"cell_type":"markdown","source":"### Data visualisations","metadata":{"id":"DmVMzXPSuYk1"}},{"cell_type":"code","source":"# Set figure and axes\nfig, ax = plt.subplots(1, 2, figsize=(22, 8))\n\n# Create boxplot showing `average_monthly_hours` distributions for `number_project`, comparing employees who stayed versus those who left\nsns.boxplot(x=\"average_monthly_hours\", y=\"number_project\", data=df, hue='left', orient='h', ax=ax[0])\nax[0].invert_yaxis()\nax[0].set_xlabel(\"Average Monthly Hours\")\nax[0].set_ylabel(\"Number of Projects\")\nax[0].set_title(\"Monthly Hours by number of projects\")\n\n# Create histogram showing distribution of `number_project`, comparing employees who stayed versus those who left\nsns.histplot(x='number_project', data=df, hue='left', multiple='dodge', shrink=3, ax=ax[1])\nax[1].set_xlabel(\"Number of Projects\")\nax[1].set_title(\"Distribution of Number of Projects\")\n\n# Display the plots\nplt.show();","metadata":{"id":"Qf0VbjX8-DBQ","execution":{"iopub.status.busy":"2023-09-28T17:02:53.98969Z","iopub.execute_input":"2023-09-28T17:02:53.990152Z","iopub.status.idle":"2023-09-28T17:02:54.995887Z","shell.execute_reply.started":"2023-09-28T17:02:53.990116Z","shell.execute_reply":"2023-09-28T17:02:54.994401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Employees who work on more projects also tend to work longer hours. This is evident from the increasing mean hours for both groups (stayed and left) as the number of projects worked increases. However, upon closer inspection, two distinct groups of employees left the company. The first group worked considerably less than their peers with the same number of projects, and the second group worked much more. The former group may have been fired or were already out the door, while the latter likely quit. It's reasonable to assume that employees in the second group were significant contributors to their projects.\n\nInterestingly, everyone with seven projects left the company, and the interquartile ranges of this group and those who left with six projects were much higher than any other group. The data suggests that the optimal number of projects for employees to work on is 3-4, as the ratio of left/stayed is much smaller for these cohorts.\n\nAssuming a work week of 40 hours and two weeks of vacation per year, the average number of working hours per month for employees working Monday-Friday is 166.67 hours per month. Except for employees who worked on two projects, every group worked considerably more than this, indicating that employees at this company may be overworked.","metadata":{}},{"cell_type":"markdown","source":"We will now investigate the average monthly hours versus the satisfaction levels","metadata":{}},{"cell_type":"code","source":"# Create a plot as needed\n# Create scatterplot of `average_monthly_hours` versus `satisfaction_level`, comparing employees who stayed versus those who left\nplt.figure(figsize=(16, 9))\nsns.scatterplot(data=df, x='average_monthly_hours', y='satisfaction_level', hue='left', alpha=0.4)\nplt.axvline(x=166.67, color='#ff6361', label='166.67 hrs./mo.', ls='--')\nplt.legend(labels=['166.67 hrs./mo.', 'left', 'stayed'])\nplt.title('Monthly hours by last evaluation score', fontsize='14');","metadata":{"id":"F8HlhjMy9X3A","execution":{"iopub.status.busy":"2023-09-28T17:04:37.622291Z","iopub.execute_input":"2023-09-28T17:04:37.622748Z","iopub.status.idle":"2023-09-28T17:04:39.170434Z","shell.execute_reply.started":"2023-09-28T17:04:37.622709Z","shell.execute_reply":"2023-09-28T17:04:39.169161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the chart provided, many employees worked between 240 and 315 hours per month. To put this into perspective, that's over 75 hours per week for an entire year. This may have contributed to their low levels of satisfaction.\n\nAdditionally, there is another group of individuals who left the company, and they had more typical working hours. However, their satisfaction levels were still relatively low, hovering around 0.4. It's difficult to say why they may have left, but it's possible that they felt pressured to work longer hours due to their peers working more.\n\nOn the other hand, a group of employees worked between 210 and 280 hours per month, and they had higher satisfaction levels ranging from 0.7 to 0.9. However, the strange distribution shape of the data suggests that there may have been some manipulation or synthetic data involved.","metadata":{}},{"cell_type":"markdown","source":"Next, we examine salary levels for different tenures.","metadata":{}},{"cell_type":"code","source":"# Set figure and axes\nfig, ax = plt.subplots(1, 2, figsize = (22,8))\n\n# Define short-tenured employees\ntenure_short = df[df['tenure'] < 7]\n\n# Define long-tenured employees\ntenure_long = df[df['tenure'] > 6]\n\n# Plot short-tenured histogram\nsns.histplot(data=tenure_short, x='tenure', hue='salary', discrete=1, \n             hue_order=['low', 'medium', 'high'], multiple='dodge', shrink=.5, ax=ax[0])\nax[0].set_title('Salary histogram by tenure: short-tenured people', fontsize='14')\n\n# Plot long-tenured histogram\nsns.histplot(data=tenure_long, x='tenure', hue='salary', discrete=1, \n             hue_order=['low', 'medium', 'high'], multiple='dodge', shrink=.4, ax=ax[1])\nax[1].set_title('Salary histogram by tenure: long-tenured people', fontsize='14');\n","metadata":{"id":"3v1uJR5y3MEy","execution":{"iopub.status.busy":"2023-09-28T17:21:30.379574Z","iopub.execute_input":"2023-09-28T17:21:30.379999Z","iopub.status.idle":"2023-09-28T17:21:31.32723Z","shell.execute_reply.started":"2023-09-28T17:21:30.37996Z","shell.execute_reply":"2023-09-28T17:21:31.325682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The plots above show that long-tenured employees were not disproportionately comprised of higher-paid employees.","metadata":{}},{"cell_type":"code","source":"# Create scatterplot of `average_monthly_hours` versus `last_evaluation`\nplt.figure(figsize=(16, 9))\nsns.scatterplot(data=df, x='average_monthly_hours', y='last_evaluation', hue='left', alpha=0.4)\nplt.axvline(x=166.67, color='#ff6361', label='166.67 hrs./mo.', ls='--')\nplt.legend(labels=['166.67 hrs./mo.', 'left', 'stayed'])\nplt.title('Monthly hours by last evaluation score', fontsize='14');","metadata":{"id":"UCVs81NILbhn","execution":{"iopub.status.busy":"2023-09-28T17:22:27.979166Z","iopub.execute_input":"2023-09-28T17:22:27.979818Z","iopub.status.idle":"2023-09-28T17:22:29.996037Z","shell.execute_reply.started":"2023-09-28T17:22:27.97963Z","shell.execute_reply":"2023-09-28T17:22:29.993395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the scatterplot above, we can deduce that two categories of employees have resigned. The first group comprises overworked employees who have performed exceptionally well. In contrast, the second group consists of employees who have worked slightly below the nominal monthly average of 166.67 hours and have lower evaluation scores. There is a correlation between the number of hours worked and the evaluation score. The plot has few employees in the upper left quadrant, indicating that working long hours does not always guarantee a good evaluation score. Furthermore, most of the employees in this company work well over 167 hours per month.","metadata":{}},{"cell_type":"code","source":"# Create plot to examine relationship between `average_monthly_hours` and `promotion_last_5years`\nplt.figure(figsize=(16, 3))\nsns.scatterplot(data=df, x='average_monthly_hours', y='promotion_last_5years', hue='left', alpha=0.4)\nplt.axvline(x=166.67, color='#ff6361', ls='--')\nplt.legend(labels=['166.67 hrs./mo.', 'left', 'stayed'])\nplt.title('Monthly hours by promotion last 5 years', fontsize='14');","metadata":{"id":"cGitCvzvdbjF","execution":{"iopub.status.busy":"2023-09-28T17:24:43.081027Z","iopub.execute_input":"2023-09-28T17:24:43.082037Z","iopub.status.idle":"2023-09-28T17:24:44.643367Z","shell.execute_reply.started":"2023-09-28T17:24:43.081975Z","shell.execute_reply":"2023-09-28T17:24:44.642118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The plot above shows the following:\n\n* very few employees who were promoted in the last five years left\n* very few employees who worked the most hours were promoted\n* all of the employees who left were working the longest hours","metadata":{}},{"cell_type":"code","source":"# Create stacked histogram to compare department distribution of employees who left to that of employees who didn't\nplt.figure(figsize=(11,8))\nsns.histplot(data=df, x='department', hue='left', discrete=1, \n             hue_order=[0, 1], multiple='dodge', shrink=.5)\nplt.xticks(rotation=45)\nplt.title('Counts of stayed/left by department', fontsize=14);","metadata":{"id":"6TyBo1uxsSpc","execution":{"iopub.status.busy":"2023-09-28T17:25:40.277464Z","iopub.execute_input":"2023-09-28T17:25:40.277929Z","iopub.status.idle":"2023-09-28T17:25:40.801322Z","shell.execute_reply.started":"2023-09-28T17:25:40.277886Z","shell.execute_reply":"2023-09-28T17:25:40.800158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There doesn't seem to be any department that differs significantly in its proportion of employees who left to those who stayed.","metadata":{}},{"cell_type":"code","source":"# Keep only numeric columns \nnumeric_cols = df_raw.select_dtypes(include=[np.number]).columns\ndf_num = df_raw[numeric_cols]\n\n# Plot a correlation heatmap\nplt.figure(figsize=(16, 9))\nheatmap = sns.heatmap(df_num.corr(), vmin=-1, vmax=1, annot=True, cmap=sns.color_palette(\"vlag\", as_cmap=True))\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':14}, pad=12);","metadata":{"id":"lfo96dwwruZd","execution":{"iopub.status.busy":"2023-09-28T17:29:58.231795Z","iopub.execute_input":"2023-09-28T17:29:58.232312Z","iopub.status.idle":"2023-09-28T17:29:59.030946Z","shell.execute_reply.started":"2023-09-28T17:29:58.232273Z","shell.execute_reply":"2023-09-28T17:29:59.029819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The correlation heatmap shows a positive relationship between the number of projects, monthly hours, and evaluation scores. Additionally, an employee's satisfaction level negatively correlates with whether they decide to leave the company.","metadata":{}},{"cell_type":"markdown","source":"### Insights\n\nBased on the observations, some workers quit their jobs due to unsatisfactory management. This decision is influenced by extended working hours, numerous projects, and decreased job contentment. Being overworked without receiving recognition or positive performance reviews can be disheartening. Additionally, a significant number of employees may be experiencing burnout. Interestingly, those who have worked at the company for over six years tend to stay.","metadata":{"id":"DeTmNVlAANLd"}},{"cell_type":"markdown","source":"## Model Building\n\n- Determine which models are most appropriate\n- Construct the model\n- Confirm model assumptions\n- Evaluate model results to determine how well your model fits the data\n","metadata":{"id":"Lca9c8XON8lc"}},{"cell_type":"markdown","source":"To figure out if an employee will leave the company, we need to predict a categorical outcome variable. This is known as a classification task, and in this case, it's binary classification. That means the outcome variable can be either 1 (indicating the employee left) or 0 (indicating the employee didn't leave). For this type of task, the most suitable models would be a Logistic Regression or a Tree-based Machine Learning mode","metadata":{}},{"cell_type":"markdown","source":"\n### Logistic Regression\n\n**Logistic Regression model assumptions**\n- Outcome variable is categorical\n- Observations are independent of each other\n- No severe multicollinearity among X variables\n- No extreme outliers\n- Linear relationship between each X variable and the logit of the outcome variable\n- Sufficiently large sample size\n\n\n\n","metadata":{"id":"Bf2BU6B1QmTg"}},{"cell_type":"code","source":"# Copy dataframe\ndf_enc = df.copy()\n\n# Encode `salary` column as ordinal numeric category\nsalary_cat = ['low', 'medium', 'high']\ndf_enc['salary'] = (df_enc['salary'].astype('category').cat.set_categories(salary_cat).cat.codes)\n\n# Dummy encode the `department` column\ndf_enc = pd.get_dummies(df_enc, drop_first=True)\n\n# Display the new dataframe\ndf_enc.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:46:01.988877Z","iopub.execute_input":"2023-09-28T17:46:01.98927Z","iopub.status.idle":"2023-09-28T17:46:02.024639Z","shell.execute_reply.started":"2023-09-28T17:46:01.989229Z","shell.execute_reply":"2023-09-28T17:46:02.023475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Heatmap to visualize how correlated variables are.","metadata":{}},{"cell_type":"code","source":"sub = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_monthly_hours', 'tenure']\nfig = plt.subplots(figsize=(8, 4))\nsns.heatmap(df_enc[sub].corr(), annot=True, cmap=\"crest\")\nplt.title('Heatmap of the dataset')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:46:34.273037Z","iopub.execute_input":"2023-09-28T17:46:34.273478Z","iopub.status.idle":"2023-09-28T17:46:34.700366Z","shell.execute_reply.started":"2023-09-28T17:46:34.273443Z","shell.execute_reply":"2023-09-28T17:46:34.699015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Outliers:**\n\nSince logistic regression is quite sensitive to outliers, it would be a good idea at this stage to remove the outliers in the tenure column that were identified earlier.","metadata":{}},{"cell_type":"code","source":"# Compute 25th percentile\npercent_25 = df['tenure'].quantile(0.25)\n\n# Compute 75th percentile\npercent_75 = df['tenure'].quantile(0.75)\n\n# Compute interquantile range\niqr = percent_75 - percent_25\n\n# Define upper and lower limits for non-oulier values in column\nupper_limit = percent_75 + 1.5 * iqr\nlower_limit = percent_25 - 1.5 * iqr","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:47:27.30177Z","iopub.execute_input":"2023-09-28T17:47:27.302204Z","iopub.status.idle":"2023-09-28T17:47:27.312401Z","shell.execute_reply.started":"2023-09-28T17:47:27.302159Z","shell.execute_reply":"2023-09-28T17:47:27.311438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select rows without outliers in `tenure` and save resulting dataframe in a new variable\ndf_logreg = df_enc[(df_enc['tenure'] >= lower_limit) & (df_enc['tenure'] <= upper_limit)]\n\n# Display first few rows of new dataframe\ndf_logreg.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:49:29.034643Z","iopub.execute_input":"2023-09-28T17:49:29.035116Z","iopub.status.idle":"2023-09-28T17:49:29.063997Z","shell.execute_reply.started":"2023-09-28T17:49:29.035082Z","shell.execute_reply":"2023-09-28T17:49:29.062814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Splits","metadata":{}},{"cell_type":"code","source":"# Separate the outcome variable from the features\ny = df_logreg['left']\nX = df_logreg.drop('left', axis=1)\n\n# Slipt the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:55:15.660331Z","iopub.execute_input":"2023-09-28T17:55:15.66084Z","iopub.status.idle":"2023-09-28T17:55:15.678843Z","shell.execute_reply.started":"2023-09-28T17:55:15.660803Z","shell.execute_reply":"2023-09-28T17:55:15.677567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression Model**","metadata":{}},{"cell_type":"code","source":"# Construct and fit a logistic model\nlog_clf = LogisticRegression(random_state=42, max_iter=500).fit(X_train, y_train)\n\n# Make predictions using the model\ny_pred = log_clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:56:10.36126Z","iopub.execute_input":"2023-09-28T17:56:10.36175Z","iopub.status.idle":"2023-09-28T17:56:11.189862Z","shell.execute_reply.started":"2023-09-28T17:56:10.361714Z","shell.execute_reply":"2023-09-28T17:56:11.188244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Confusion Matrix**","metadata":{}},{"cell_type":"code","source":"# Confusion Matrix\nlog_cm = confusion_matrix(y_test, y_pred, labels=log_clf.classes_)\n\n# Display for the confusion matrix\nlog_disp = ConfusionMatrixDisplay(confusion_matrix=log_cm, display_labels=log_clf.classes_)\n\n# Plot confusion matrix\nlog_disp.plot(values_format='')\n\n# Display plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T17:56:36.43503Z","iopub.execute_input":"2023-09-28T17:56:36.435534Z","iopub.status.idle":"2023-09-28T17:56:36.676576Z","shell.execute_reply.started":"2023-09-28T17:56:36.435497Z","shell.execute_reply":"2023-09-28T17:56:36.675134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The upper-left quadrant displays the number of true negatives. The upper-right quadrant displays the number of false positives. The bottom-left quadrant displays the number of false negatives. The bottom-right quadrant displays the number of true positives.\n\nTrue negatives: The number of people who did not leave that the model accurately predicted did not leave.\n\nFalse positives: The number of people who did not leave the model inaccurately predicted as leaving.\n\nFalse negatives: The number of people who left that the model inaccurately predicted did not leave\n\nTrue positives: The number of people who left the model accurately predicted as leaving\n\nA perfect model would yield all true negatives and true positives, and no false negatives or false positives.","metadata":{}},{"cell_type":"markdown","source":"**Imbalance Check**\n\nChecking the value counts in the `left` column. Since this is a binary classification task, the class balance informs the way you interpret accuracy metrics.","metadata":{}},{"cell_type":"code","source":"df_logreg['left'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:01:07.973917Z","iopub.execute_input":"2023-09-28T18:01:07.97434Z","iopub.status.idle":"2023-09-28T18:01:07.988505Z","shell.execute_reply.started":"2023-09-28T18:01:07.974308Z","shell.execute_reply":"2023-09-28T18:01:07.98692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The split between the two classes is 83% to 17%, indicating that the data is not perfectly balanced but not too imbalanced. If the data was more severely imbalanced, resample it to achieve a more balanced distribution. However, in this instance, you can use the data without altering the class balance and proceed with model evaluation.","metadata":{}},{"cell_type":"markdown","source":"**Metrics Report**","metadata":{}},{"cell_type":"code","source":"# Create classification report for logistic regression model\ntarget_names = ['Predicted would not leave', 'Predicted would leave']\nreport = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n\n# Convert to dataframe \nreport_df = pd.DataFrame(report).transpose()\n\n# Display results\nreport_df","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:08:32.356122Z","iopub.execute_input":"2023-09-28T18:08:32.356638Z","iopub.status.idle":"2023-09-28T18:08:32.385523Z","shell.execute_reply.started":"2023-09-28T18:08:32.356586Z","shell.execute_reply":"2023-09-28T18:08:32.384514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to tailor the dataframe so as to be the base for the metrics that will be used in the other models","metadata":{}},{"cell_type":"code","source":"## Extracting relevant data from the report_df\n\n# Extracting the last row\nresults = report_df.tail(1).reset_index(drop=True)\n\n# Rename 'f1-score' column\nresults = results.rename(columns={'f1-score' : 'F1'})\n\n# Adding a new column \"model\" at the beginning with sample values\nresults.insert(0, 'model', ['logistic regression'])\n\n# Dropping the last column (\"support\") from the DataFrame\nresults.drop(columns=['support'], inplace=True)\n\n# Adding 'accuracy' and 'auc' columns to the DataFrame\nresults['accuracy'] = report_df.loc['accuracy'][0]\nresults['AUC'] = roc_auc_score(y_test, y_pred)\n\n# Display the `result` dataframe\nresults","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:08:56.607334Z","iopub.execute_input":"2023-09-28T18:08:56.607842Z","iopub.status.idle":"2023-09-28T18:08:56.637135Z","shell.execute_reply.started":"2023-09-28T18:08:56.607805Z","shell.execute_reply":"2023-09-28T18:08:56.63525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The table above shows that the logistic regression model achieved a precision of 79%, recall of 82%, f1-score of 80%, and accuracy of 82% with and area under the curve (AUC) of 60%.","metadata":{}},{"cell_type":"markdown","source":"## Tree-based Model\n\nThis approach covers implementation of Decision Tree and Random Forest.","metadata":{}},{"cell_type":"markdown","source":"### Decision tree","metadata":{}},{"cell_type":"code","source":"# Instantiate a decision tree model\ntree = DecisionTreeClassifier(random_state=42)\n\n# Dictionnary of hyperparameters\ncv_params = {'max_depth' : [4, 6, 8, None],\n             'min_samples_leaf' : [1, 2, 5],\n             'min_samples_split' : [2, 4, 6]}\n\n# Scoring\nscoring = {'f1' : 'f1', \n           'accuracy' : 'accuracy', \n           'precision' : 'precision', \n           'recall' : 'recall', \n           'roc_auc' : 'roc_auc'}\n\n# Instantiate GridSearch\ntree_cv1 = GridSearchCV(tree, cv_params, scoring=scoring, cv=5, refit='roc_auc', verbose=True, n_jobs=-1) \n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:13:32.986953Z","iopub.execute_input":"2023-09-28T18:13:32.988538Z","iopub.status.idle":"2023-09-28T18:13:32.996394Z","shell.execute_reply.started":"2023-09-28T18:13:32.988479Z","shell.execute_reply":"2023-09-28T18:13:32.995227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fit the decision tree model to the training data.","metadata":{}},{"cell_type":"code","source":"%%time\ntree_cv1.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:13:50.393522Z","iopub.execute_input":"2023-09-28T18:13:50.394009Z","iopub.status.idle":"2023-09-28T18:13:55.511582Z","shell.execute_reply.started":"2023-09-28T18:13:50.393974Z","shell.execute_reply":"2023-09-28T18:13:55.509929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best parameters\ntree_cv1.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:14:31.493875Z","iopub.execute_input":"2023-09-28T18:14:31.49446Z","iopub.status.idle":"2023-09-28T18:14:31.503736Z","shell.execute_reply.started":"2023-09-28T18:14:31.494381Z","shell.execute_reply":"2023-09-28T18:14:31.50265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best score\ntree_cv1.best_score_","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:14:35.372296Z","iopub.execute_input":"2023-09-28T18:14:35.372861Z","iopub.status.idle":"2023-09-28T18:14:35.381985Z","shell.execute_reply.started":"2023-09-28T18:14:35.372817Z","shell.execute_reply":"2023-09-28T18:14:35.380831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is a strong AUC score, which shows that this model can predict employees who will leave very well.\n\nNext, you can write a function that will help you extract all the scores from the grid search.\n","metadata":{}},{"cell_type":"code","source":"def make_results(model_name:str, model_object, metric:str):\n    '''\n    Arguments:\n        model_name (string): what you want the model to be called in the output table\n        model_object: a fit GridSearchCV object\n        metric (string): precision, recall, f1, accuracy, or auc\n  \n    Returns a pandas df with the F1, recall, precision, accuracy, and auc scores\n    for the model with the best mean 'metric' score across all validation folds.  \n    '''\n\n    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n    metric_dict = {'auc': 'mean_test_roc_auc',\n                   'precision': 'mean_test_precision',\n                   'recall': 'mean_test_recall',\n                   'f1': 'mean_test_f1',\n                   'accuracy': 'mean_test_accuracy'\n                  }\n\n    # Get all the results from the CV and put them in a df\n    cv_results = pd.DataFrame(model_object.cv_results_)\n\n    # Isolate the row of the df with the max(metric) score\n    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n\n    # Extract Accuracy, precision, recall, and f1 score from that row\n    auc = best_estimator_results.mean_test_roc_auc\n    f1 = best_estimator_results.mean_test_f1\n    recall = best_estimator_results.mean_test_recall\n    precision = best_estimator_results.mean_test_precision\n    accuracy = best_estimator_results.mean_test_accuracy\n  \n    # Create table of results\n    table = pd.DataFrame()\n    table = pd.DataFrame({'model': [model_name],\n                          'precision': [precision],\n                          'recall': [recall],\n                          'F1': [f1],\n                          'accuracy': [accuracy],\n                          'AUC': [auc]\n                        })\n  \n    return table","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:15:11.004166Z","iopub.execute_input":"2023-09-28T18:15:11.004669Z","iopub.status.idle":"2023-09-28T18:15:11.019719Z","shell.execute_reply.started":"2023-09-28T18:15:11.004631Z","shell.execute_reply":"2023-09-28T18:15:11.01783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use the function just defined to get all the scores from grid search.","metadata":{}},{"cell_type":"code","source":"# Get all CV scores\ntree1_cv_results = make_results('decision tree cv', tree_cv1, 'auc')\n\n# Update `results` DataFrame\nresults = pd.concat([results, tree1_cv_results], axis=0)\n\n# Sort 'results' by F1-score\nresults = results.sort_values(by='F1', ascending=False).reset_index(drop=True)\n\n# Display `results` Dataframe\nresults","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:15:23.334333Z","iopub.execute_input":"2023-09-28T18:15:23.334757Z","iopub.status.idle":"2023-09-28T18:15:23.359918Z","shell.execute_reply.started":"2023-09-28T18:15:23.334722Z","shell.execute_reply":"2023-09-28T18:15:23.358332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All of these scores from the decision tree model are strong indicators of good model performance.\n\nRecall that decision trees can be vulnerable to overfitting, and random forests avoid overfitting by incorporating multiple trees to make predictions.","metadata":{}},{"cell_type":"markdown","source":"Define a function that gets all the scores from a model's predictions.","metadata":{}},{"cell_type":"code","source":"def get_scores(model_name:str, model, X_test_data, y_test_data):\n    '''\n    Generate a table of test scores.\n\n    In: \n        model_name (string):  How you want your model to be named in the output table\n        model:                A fit GridSearchCV object \n        X_test_data:          numpy array of X_test data\n        y_test_data:          numpy array of y_test data\n\n    Out: pandas df of precision, recall, f1, accuracy, and AUC scores for your model\n    '''\n\n    preds = model.best_estimator_.predict(X_test_data)\n\n    auc = roc_auc_score(y_test_data, preds)\n    accuracy = accuracy_score(y_test_data, preds)\n    precision = precision_score(y_test_data, preds)\n    recall = recall_score(y_test_data, preds)\n    f1 = f1_score(y_test_data, preds)\n\n    table = pd.DataFrame({'model': [model_name],\n                          'precision': [precision], \n                          'recall': [recall],\n                          'F1': [f1],\n                          'accuracy': [accuracy],\n                          'AUC': [auc]\n                         })\n  \n    return table","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:22:08.156253Z","iopub.execute_input":"2023-09-28T18:22:08.157396Z","iopub.status.idle":"2023-09-28T18:22:08.167903Z","shell.execute_reply.started":"2023-09-28T18:22:08.157349Z","shell.execute_reply":"2023-09-28T18:22:08.165889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get predictions from test data\ntree_test_scores = get_scores('decision tree test', tree_cv1, X_test, y_test)\n\n# Update `results` DataFrame\nresults = pd.concat([results, tree_test_scores], axis=0)\n\n# Sort 'results' by F1-score\nresults = results.sort_values(by='F1', ascending=False).reset_index(drop=True)\n\n# Display `results` Dataframe\nresults","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:22:12.076458Z","iopub.execute_input":"2023-09-28T18:22:12.076879Z","iopub.status.idle":"2023-09-28T18:22:12.112965Z","shell.execute_reply.started":"2023-09-28T18:22:12.076848Z","shell.execute_reply":"2023-09-28T18:22:12.111613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tree Visualisation**","metadata":{}},{"cell_type":"code","source":"# Extract column names\nfeature_names = list(X.columns)\n\n# Class names\nclass_names = ['stayed', 'left']\n\n# Plot the tree\nplt.figure(figsize=(85,20))\nplot_tree(tree_cv1.best_estimator_, \n          max_depth=6, fontsize=14, \n          feature_names=feature_names, \n          class_names=class_names, \n          filled=True);\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T20:30:02.305741Z","iopub.execute_input":"2023-09-28T20:30:02.306301Z","iopub.status.idle":"2023-09-28T20:30:04.772725Z","shell.execute_reply.started":"2023-09-28T20:30:02.306265Z","shell.execute_reply":"2023-09-28T20:30:04.771073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Importance**","metadata":{}},{"cell_type":"code","source":"tree_importances = pd.DataFrame(tree_cv1.best_estimator_.feature_importances_, \n                                 columns=['gini_importance'], \n                                 index=X.columns\n                                )\ntree_importances = tree_importances.sort_values(by='gini_importance', ascending=False)\n\n# Only extract the features with importances > 0\ntree_importances = tree_importances[tree_importances['gini_importance'] != 0]\ntree_importances","metadata":{"execution":{"iopub.status.busy":"2023-09-28T20:30:09.515277Z","iopub.execute_input":"2023-09-28T20:30:09.515778Z","iopub.status.idle":"2023-09-28T20:30:09.535072Z","shell.execute_reply.started":"2023-09-28T20:30:09.515743Z","shell.execute_reply":"2023-09-28T20:30:09.533851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=tree_importances, x=\"gini_importance\", y=tree_importances.index, orient='h')\nplt.title(\"Decision Tree: Feature Importances for Employee Leaving\", fontsize=12)\nplt.ylabel(\"Feature\")\nplt.xlabel(\"Importance\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T20:31:40.686589Z","iopub.execute_input":"2023-09-28T20:31:40.687276Z","iopub.status.idle":"2023-09-28T20:31:40.986795Z","shell.execute_reply.started":"2023-09-28T20:31:40.687234Z","shell.execute_reply":"2023-09-28T20:31:40.985114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random forest\n\nConstruct a random forest model and set up cross-validated grid-search to exhuastively search for the best model parameters.","metadata":{}},{"cell_type":"code","source":"# Instantiate model\nrf = RandomForestClassifier(random_state=42)\n\n# Hyperparameters\ncv_params = {'max_depth' : [1, 3, 5, 10, None],\n             'max_features' : [0.5, 1.0],\n             'max_samples' : [0.5, 0.7, 1.0],\n             'min_samples_leaf' : [1, 2, 5],\n             'min_samples_split' : [2, 3, 5],\n             'n_estimators' : [300, 500]}\n\n# Scoring\nscoring = {'accuracy' : 'accuracy',\n           'precision' : 'precision',\n           'f1' : 'f1',\n           'recall' : 'recall',\n           'roc_auc' : 'roc_auc'}\n\n# Instantiate GridSearch\nrf_cv1 = GridSearchCV(rf, cv_params, scoring=scoring, cv=5, refit='roc_auc', n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T18:23:50.144665Z","iopub.execute_input":"2023-09-28T18:23:50.145089Z","iopub.status.idle":"2023-09-28T18:23:50.153513Z","shell.execute_reply.started":"2023-09-28T18:23:50.145054Z","shell.execute_reply":"2023-09-28T18:23:50.152298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Fit the model on test data\nrf_cv1.fit(X_train, y_train)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-09-28T18:32:44.25166Z","iopub.execute_input":"2023-09-28T18:32:44.252126Z","iopub.status.idle":"2023-09-28T19:25:11.739308Z","shell.execute_reply.started":"2023-09-28T18:32:44.252087Z","shell.execute_reply":"2023-09-28T19:25:11.737395Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Define a path to the folder where you want to save the model\npath = os.path.join(os.getcwd(), 'model')\n\n# Create the 'model/' directory if it doesn't exist\nif not os.path.exists(path):\n    os.makedirs(path)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:27:40.544174Z","iopub.execute_input":"2023-09-28T19:27:40.544608Z","iopub.status.idle":"2023-09-28T19:27:40.55131Z","shell.execute_reply.started":"2023-09-28T19:27:40.544576Z","shell.execute_reply":"2023-09-28T19:27:40.550074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define functions to pickle the model and read in the model.","metadata":{}},{"cell_type":"code","source":"def write_pickle(path, model_object, save_as:str):\n    '''\n    In: \n        path:         path of folder where you want to save the pickle\n        model_object: a model you want to pickle\n        save_as:      filename for how you want to save the model\n\n    Out: A call to pickle the model in the folder indicated\n    '''    \n\n    # Create the full path for saving the model\n    full_path = os.path.join(path, save_as + '.pickle')\n\n    with open(full_path, 'wb') as to_write:\n        pickle.dump(model_object, to_write)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:27:45.824502Z","iopub.execute_input":"2023-09-28T19:27:45.824912Z","iopub.status.idle":"2023-09-28T19:27:45.832736Z","shell.execute_reply.started":"2023-09-28T19:27:45.824881Z","shell.execute_reply":"2023-09-28T19:27:45.831557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_pickle(path, saved_model_name:str):\n    '''\n    In: \n        path:             path to folder where you want to read from\n        saved_model_name: filename of pickled model you want to read in\n\n    Out: \n        model: the pickled model \n    '''\n    \n    # Create the full path for saving the model\n    full_path = os.path.join(path, saved_model_name + '.pickle')\n\n    with open(full_path, 'rb') as to_read:\n        model = pickle.load(to_read)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:28:10.277393Z","iopub.execute_input":"2023-09-28T19:28:10.277906Z","iopub.status.idle":"2023-09-28T19:28:10.285803Z","shell.execute_reply.started":"2023-09-28T19:28:10.277866Z","shell.execute_reply":"2023-09-28T19:28:10.284107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Write pickle\nwrite_pickle(path, rf_cv1, 'hr_rf1')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:28:16.17232Z","iopub.execute_input":"2023-09-28T19:28:16.172815Z","iopub.status.idle":"2023-09-28T19:28:16.214295Z","shell.execute_reply.started":"2023-09-28T19:28:16.172777Z","shell.execute_reply":"2023-09-28T19:28:16.2131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read pickle\nrf1 = read_pickle(path, 'hr_rf1')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:28:28.275896Z","iopub.execute_input":"2023-09-28T19:28:28.276402Z","iopub.status.idle":"2023-09-28T19:28:28.3103Z","shell.execute_reply.started":"2023-09-28T19:28:28.276363Z","shell.execute_reply":"2023-09-28T19:28:28.309016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Identify the best AUC score achieved by the random forest model on the training set.","metadata":{}},{"cell_type":"code","source":"# Check best AUC score on CV\nrf1.best_score_","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:28:32.024166Z","iopub.execute_input":"2023-09-28T19:28:32.024892Z","iopub.status.idle":"2023-09-28T19:28:32.031982Z","shell.execute_reply.started":"2023-09-28T19:28:32.024855Z","shell.execute_reply":"2023-09-28T19:28:32.030709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Identify the optimal values for the parameters of the random forest model.","metadata":{}},{"cell_type":"code","source":"# Check best params\nrf1.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:28:41.347354Z","iopub.execute_input":"2023-09-28T19:28:41.347888Z","iopub.status.idle":"2023-09-28T19:28:41.356854Z","shell.execute_reply.started":"2023-09-28T19:28:41.347849Z","shell.execute_reply":"2023-09-28T19:28:41.355148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all CV scores\nrf1_cv_results = make_results('random forest cv', rf1, 'auc')\n\n# Update `results` DataFrame\nresults = pd.concat([results, rf1_cv_results], axis=0)\n\n# Sort 'results' by F1-score\nresults = results.sort_values(by='F1', ascending=False).reset_index(drop=True)\n\n# Display `results` Dataframe\nresults","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:28:54.394321Z","iopub.execute_input":"2023-09-28T19:28:54.396073Z","iopub.status.idle":"2023-09-28T19:28:54.422869Z","shell.execute_reply.started":"2023-09-28T19:28:54.396012Z","shell.execute_reply":"2023-09-28T19:28:54.42151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get predictions on test data\nrf1_test_scores = get_scores('random forest test', rf1, X_test, y_test)\n\n# Update `results` DataFrame\nresults = pd.concat([results, rf1_test_scores], axis=0)\n\n# Sort 'results' by F1-score\nresults = results.sort_values(by='F1', ascending=False).reset_index(drop=True)\n\n# Display `results` Dataframe\nresults","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:32:33.39494Z","iopub.execute_input":"2023-09-28T19:32:33.395589Z","iopub.status.idle":"2023-09-28T19:32:33.557115Z","shell.execute_reply.started":"2023-09-28T19:32:33.39554Z","shell.execute_reply":"2023-09-28T19:32:33.555955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pivot the `results` table\nresults_long = pd.melt(results, 'model')\nresults_long = results_long.rename(columns={'variable' : 'metric'})\nresults_long","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:33:08.913079Z","iopub.execute_input":"2023-09-28T19:33:08.91371Z","iopub.status.idle":"2023-09-28T19:33:08.935473Z","shell.execute_reply.started":"2023-09-28T19:33:08.913661Z","shell.execute_reply":"2023-09-28T19:33:08.934472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Comparing Models' results**","metadata":{}},{"cell_type":"code","source":"# Initialize the figure\nfig, ax = plt.subplots(2, 1, figsize=(12, 12))\n\n# Barplot with Metrics on x-axis and new color scheme ('husl')\nsns.barplot(x='metric', y='value', hue='model', data=results_long, ax=ax[0])\n\n# Find the highest value for each metric to highlight the corresponding bar\nfor metric in results_long['metric'].unique():\n    highest_value = results_long[results_long['metric'] == metric]['value'].max()\n    # Highlight the bar with highest value for each metric\n    for p in ax[0].patches:\n        if p.get_height() == highest_value and p.get_x() >= list(results_long['metric'].unique()).index(metric) - 0.5:\n            p.set_edgecolor('black')\n            p.set_linewidth(1)\n\nax[0].set_title('Bar Chart of Model Evaluation Metrics (Metrics on x-axis)')\nax[0].set_ylabel('Value')\nax[0].set_xlabel('Metrics')\n\n# Move legend to the bottom for the barplot\nax[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=5)\n\n# Line Graph with Metrics on x-axis and new color scheme ('dark')\nsns.lineplot(x='metric', y='value', hue='model', data=results_long, ax=ax[1], marker='o')\nax[1].set_title('Line Graph of Model Evaluation Metrics (Metrics on x-axis)')\nax[1].set_ylabel('Value')\nax[1].set_xlabel('Metrics')\n\n# Remove legend from the line graph\nax[1].legend_.remove()\n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:56:54.641036Z","iopub.execute_input":"2023-09-28T19:56:54.642569Z","iopub.status.idle":"2023-09-28T19:56:55.62851Z","shell.execute_reply.started":"2023-09-28T19:56:54.6425Z","shell.execute_reply":"2023-09-28T19:56:55.627281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Choices Based on Metrics:**\n\n`Random Forest Test`:Excels in Precision, F1 Score, and Accuracy. This model is less likely to falsely identify loyal employees as risks and offers an excellent general-purpose solution.\n\n`Decision Tree Test`: Best in Recall. This model would be suitable if the company is more focused on capturing as many flight risks as possible, even at the risk of some false positives.\n\n`Random Forest CV`:Best in AUC. This suggests that the model is excellent in differentiating between the classes. \n\n\n**Recommendation:**\n\nGiven the high costs associated with false positives (misidentifying loyal employees) and false negatives (failing to identify employees who will leave), a balanced approach might be best.\n`Random Forest Test` is the most balanced model, excelling in precision, F1 score, and accuracy. It's less likely to misclassify employees, enabling the HR department to take targeted actions.","metadata":{}},{"cell_type":"code","source":"# Generate array of values for confusion matrix\npreds = rf1.best_estimator_.predict(X_test)\ncm = confusion_matrix(y_test, preds, labels=rf1.classes_)\n\n# Plot confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                             display_labels=rf1.classes_)\ndisp.plot(values_format='');","metadata":{"execution":{"iopub.status.busy":"2023-09-28T19:34:00.86963Z","iopub.execute_input":"2023-09-28T19:34:00.870102Z","iopub.status.idle":"2023-09-28T19:34:01.30486Z","shell.execute_reply.started":"2023-09-28T19:34:00.870067Z","shell.execute_reply":"2023-09-28T19:34:01.303467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**interpretation:**\n\n* High True Negative (TN): The model correctly identified a large number of employees who are not at risk of quitting or getting fired (TN = 2316). This is a strong indicator that the model is effective at ruling out employees who are not at risk.\n* High True Positive (TP): The model also correctly identified a substantial number of employees who are at risk (TP = 434). This shows that the model is also effective at flagging employees who are actually at risk.\n* Low False Positive (FP): The model incorrectly flagged only a small number of employees as being at risk when they are not (FP = 37). This could lead to unnecessary interventions but is relatively low.\n* Low False Negative (FN): The model missed a very low number of employees who are at risk but were classified as not being at risk (FN = 5). This is also a good sign, as missing at-risk employees could have been detrimental.\n\nOverall, this is a robust model for identifying employees who are and are not at risk of quitting or getting fired, with a low rate of false positives and false negatives.","metadata":{}},{"cell_type":"markdown","source":"**Feature Importance**","metadata":{}},{"cell_type":"code","source":"# Get feature importances\nfeat_impt = rf1.best_estimator_.feature_importances_\n\n# Get indices of top 10 features\nind = np.argpartition(rf1.best_estimator_.feature_importances_, -10)[-10:]\n\n# Get column labels of top 10 features \nfeat = X.columns[ind]\n\n# Filter `feat_impt` to consist of top 10 feature importances\nfeat_impt = feat_impt[ind]\n\ny_df = pd.DataFrame({\"Feature\":feat,\"Importance\":feat_impt})\ny_sort_df = y_df.sort_values(\"Importance\")\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\ny_sort_df.plot(kind='barh',ax=ax1,x=\"Feature\",y=\"Importance\")\n\nax1.set_title(\"Random Forest: Feature Importances for Employee Leaving\", fontsize=12)\nax1.set_ylabel(\"Feature\")\nax1.set_xlabel(\"Importance\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T20:33:10.315831Z","iopub.execute_input":"2023-09-28T20:33:10.31631Z","iopub.status.idle":"2023-09-28T20:33:10.694236Z","shell.execute_reply.started":"2023-09-28T20:33:10.316277Z","shell.execute_reply":"2023-09-28T20:33:10.692986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results and Evaluation","metadata":{}},{"cell_type":"markdown","source":"### Evaluation metrics\n\n* **AUC** is the area under the ROC curve; it's also considered the probability that the model ranks a random positive example more highly than a random negative example.\n* **Precision** measures the proportion of data points predicted as True that are actually True, in other words, the proportion of positive predictions that are true positives.\n* **Recall** measures the proportion of data points that are predicted as True, out of all the data points that are actually True. In other words, it measures the proportion of positives that are correctly classified.\n* **Accuracy** measures the proportion of data points that are correctly classified.\n* **F1-score** is an aggregation of precision and recall.\n","metadata":{}},{"cell_type":"markdown","source":"## Model results\n\n**1. Logistic Regression**\n\nOn the test set, the logistic regression model achieved the following:\n- precision : 80%, \n- recall : 83%, \n- f1-score : 80% (all weighted averages), \n- accuracy : 83%, \n- AUC (area under the curve) : 60%\n\n**2. Tree-based Machine Learning**\n\nFor both models, the test results were higher than the cross-validation's.\n\n**Decision Tree**\n\nOn the test set, the decision tree model achieved the following:\n- precision : 96%, \n- recall : 92%, \n- f1-score : 94% (all weighted averages), \n- accuracy : 98%, \n- AUC (area under the curve) : 96%\n\n**Random Forest**\n\nOn the test set, the random forest model achieved the following:\n- precision : 98%, \n- recall : 92%, \n- f1-score : 95% (all weighted averages), \n- accuracy : 98%, \n- AUC (area under the curve) : 95%\n\nWhile the decision tree model has a higher AUC compared to the random forest, it can still be concluded that the random forest model is superior overall.\n","metadata":{}},{"cell_type":"markdown","source":"## Recommendations\n\nTo ensure that employees at the company are well-rested and remain satisfied, stakeholders should consider implementing the following recommendations.\n- Limit the number of projects that employees can work on. \n- Promote employees who have been with the company for at least four years or investigate why these tenured employees are dissatisfied. \n- Stakeholders could either reward employees for working longer hours or limit their hours. \n- Inform employees about the company's overtime pay policies and clarify expectations around workload and time off. Company-wide and within-team discussions can also be held to address work culture. \n- Evaluation scores should be reserved for employees who work less than 200+ hours per month, and a proportionate scale should be used to reward employees who contribute more effort.","metadata":{}}]}